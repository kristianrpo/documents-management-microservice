name: Documents Microservice CD

on:
  push:
    branches: [main]

permissions:
  contents: read

env:
  TF_BACKEND_BUCKET: ${{ secrets.TF_BACKEND_BUCKET }}
  TF_BACKEND_KEY: infra/terraform/aws/terraform.tfstate
  TF_BACKEND_REGION: ${{ secrets.AWS_REGION }}
  TF_BACKEND_DDB_TABLE: ${{ secrets.TF_BACKEND_DDB_TABLE }}

jobs:
  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435

      - name: Log in to Docker Hub
        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Extract metadata (tags, labels) for Docker
        id: meta
        uses: docker/metadata-action@8e5442c4ef9f78752691e2d8f8d19755c6f78e81
        with:
          images: ${{ secrets.DOCKERHUB_USERNAME }}/documents-microservice
          tags: |
            type=sha,prefix=main-
            type=raw,value=latest

      - name: Build and push Docker image
        uses: docker/build-push-action@48aba3b46d1b1fec4febb7c5d0c644b249a11355
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      - name: Image digest
        run: echo ${{ steps.meta.outputs.digest }}

  sonar-tracking:
    name: SonarCloud Tracking (Main Branch)
    runs-on: ubuntu-latest
    needs: build-and-push
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: "1.25"
          cache: true

      - name: Install dependencies
        run: |
          go mod download
          go mod tidy

      - name: Install golangci-lint
        run: |
          curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Run golangci-lint
        run: |
          golangci-lint run --output.checkstyle.path=golangci-lint-report.xml || true

      - name: Run Tests with Coverage
        run: |
          echo "Running unit tests..."
          go test ./internal/.../tests/... -v
          
          echo "Generating coverage report..."
          go test -coverpkg=./internal/... ./internal/.../tests -coverprofile=coverage.out -covermode=atomic
          
          echo "Coverage Summary:"
          go tool cover -func=coverage.out | tail -1

      - name: SonarCloud Scan (Main Branch)
        uses: SonarSource/sonarcloud-github-action@ffc3010689be73b8e5ae0c57ce35968afd7909e8 # v5.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          args: >
            -Dsonar.branch.name=main

  infra-apply:
    name: Provision Microservice AWS Resources (Terraform) - Phase 1
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init (infra - remote state)
        working-directory: infra/terraform/aws
        run: |
          terraform init -input=false -upgrade \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Terraform Validate (infra)
        working-directory: infra/terraform/aws
        run: terraform validate

      - name: Terraform Apply (microservice resources)
        working-directory: infra/terraform/aws
        run: |
          terraform apply -auto-approve -input=false \
            -var "tf_backend_bucket=$TF_BACKEND_BUCKET"

  k8s-apply:
    name: Deploy Monitoring Stack (kube-prometheus) - Phase 2
    runs-on: ubuntu-latest
    needs: [infra-apply]
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init (infra dir to read outputs)
        working-directory: infra/terraform/aws
        run: |
          terraform init -input=false \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Read infra outputs (EKS cluster info from shared infra)
        id: infra_outputs
        run: |
          echo "CLUSTER_NAME=$(terraform -chdir=infra/terraform/aws output -raw cluster_name)" >> $GITHUB_OUTPUT
          echo "CLUSTER_ENDPOINT=$(terraform -chdir=infra/terraform/aws output -raw cluster_endpoint)" >> $GITHUB_OUTPUT
          echo "CLUSTER_CA=$(terraform -chdir=infra/terraform/aws output -raw cluster_ca_certificate)" >> $GITHUB_OUTPUT

      - name: Terraform Init (k8s - remote state)
        working-directory: k8s/terraform/aws
        run: |
          terraform init -input=false -upgrade \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=k8s/terraform/aws/terraform.tfstate" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Import existing K8s/Helm resources into state (idempotency)
        working-directory: k8s/terraform/aws
        env:
          TF_VAR_aws_region: ${{ secrets.AWS_REGION }}
          TF_VAR_cluster_name: ${{ steps.infra_outputs.outputs.CLUSTER_NAME }}
          TF_VAR_cluster_endpoint: ${{ steps.infra_outputs.outputs.CLUSTER_ENDPOINT }}
          TF_VAR_cluster_ca_certificate: ${{ steps.infra_outputs.outputs.CLUSTER_CA }}
        run: |
          set -euo pipefail
          # Importar namespace 'monitoring' si ya existe
          terraform import -input=false -no-color kubernetes_namespace.monitoring monitoring || true
          # Importar ConfigMap del dashboard si ya existe
          terraform import -input=false -no-color kubernetes_config_map.grafana_dashboard monitoring/documents-service-dashboard || true
          # Importar release Helm si ya existe
          terraform import -input=false -no-color helm_release.kube_prometheus_stack monitoring/kube-prometheus-stack || true

      - name: Terraform Validate (k8s)
        working-directory: k8s/terraform/aws
        run: terraform validate

      - name: Terraform Apply (monitoring stack)
        working-directory: k8s/terraform/aws
        env:
          TF_LOG: INFO
        run: |
          terraform apply -auto-approve -input=false \
            -var "aws_region=${{ secrets.AWS_REGION }}" \
            -var "cluster_name=${{ steps.infra_outputs.outputs.CLUSTER_NAME }}" \
            -var "cluster_endpoint=${{ steps.infra_outputs.outputs.CLUSTER_ENDPOINT }}" \
            -var "cluster_ca_certificate=${{ steps.infra_outputs.outputs.CLUSTER_CA }}"

  app-deploy:
    name: Deploy Application to EKS (kubectl/kustomize) - Phase 3
    runs-on: ubuntu-latest
    needs: [build-and-push, k8s-apply]
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Install kubectl
        run: |
          KUBECTL_VERSION=$(curl -sL https://dl.k8s.io/release/stable.txt)
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/kubectl
          kubectl version --client

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Setup Terraform (to read outputs from remote state)
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init (infra dir to read outputs)
        working-directory: infra/terraform/aws
        run: |
          terraform init -input=false \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Update kubeconfig (connect kubectl to EKS)
        run: |
          CLUSTER_NAME=$(terraform -chdir=infra/terraform/aws output -raw cluster_name)
          aws eks update-kubeconfig --name "$CLUSTER_NAME" --region ${{ secrets.AWS_REGION }}

      - name: Prepare AWS Secrets for app
        env:
          TF_DIR: infra/terraform/aws
        run: |
          SECRET_NAME=$(terraform -chdir=$TF_DIR output -raw secretsmanager_secret_name)
          RABBIT_URL=$(terraform -chdir=$TF_DIR output -raw rabbitmq_amqp_url)
          S3_BUCKET=$(terraform -chdir=$TF_DIR output -raw s3_bucket)
          PROCESSED_MSGS_TABLE=$(terraform -chdir=$TF_DIR output -raw rabbitmq_processed_messages_table_name)
          aws secretsmanager put-secret-value \
            --secret-id "$SECRET_NAME" \
            --secret-string "$(jq -n \
              --arg port "${{ secrets.APP_PORT }}" \
              --arg table "$(terraform -chdir=$TF_DIR output -raw dynamodb_table)" \
              --arg processed_table "$PROCESSED_MSGS_TABLE" \
              --arg region "${{ secrets.AWS_REGION }}" \
              --arg bucket "$S3_BUCKET" \
              --arg rabbit "$RABBIT_URL" \
              --arg consumer_queue "${{ secrets.RABBITMQ_CONSUMER_QUEUE }}" \
              --arg auth_request_queue "${{ secrets.RABBITMQ_AUTH_REQUEST_QUEUE }}" \
              --arg auth_result_queue "${{ secrets.RABBITMQ_AUTH_RESULT_QUEUE }}" \
              '{
                APP_PORT: $port,
                DYNAMODB_TABLE: $table,
                DYNAMODB_PROCESSED_MESSAGES_TABLE: $processed_table,
                DYNAMODB_ENDPOINT: "",
                AWS_REGION: $region,
                S3_BUCKET: $bucket,
                S3_ENDPOINT: "",
                S3_USE_PATH_STYLE: "false",
                S3_PUBLIC_BASE_URL: "",
                RABBITMQ_URL: $rabbit,
                RABBITMQ_CONSUMER_QUEUE: $consumer_queue,
                RABBITMQ_AUTH_REQUEST_QUEUE: $auth_request_queue,
                RABBITMQ_AUTH_RESULT_QUEUE: $auth_result_queue
              }')" || true

      - name: Render K8s templates with infra outputs
        env:
          TF_DIR: infra/terraform/aws
        run: |
          set -euo pipefail
          SECRET_NAME=$(terraform -chdir=$TF_DIR output -raw secretsmanager_secret_name)
          REGION='${{ secrets.AWS_REGION }}'
          IRSA_ROLE=$(terraform -chdir=$TF_DIR output -raw irsa_role_arn)
          # Sustituir placeholders en External Secrets
          sed -i "s|__AWS_REGION__|$REGION|g" k8s/overlays/prod/externalsecrets.yaml
          sed -i "s|__AWS_SECRET_NAME__|$SECRET_NAME|g" k8s/overlays/prod/externalsecrets.yaml
          # Sustituir placeholder de IRSA role en ServiceAccount
          sed -i "s|IRSA_ROLE_ARN|$IRSA_ROLE|g" k8s/base/service-account.yaml

      - name: Deploy application
        run: |
          kubectl apply -k k8s/overlays/prod/
          kubectl -n documents rollout status deploy/documents-service --timeout=180s

      - name: Display Access Information
        run: |
          echo "=== Deployment Summary ==="
          echo ""
          echo "Application Ingress (ALB):"
          kubectl -n documents get ingress documents-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "Pending..."
          echo ""
          echo ""
          echo "Grafana LoadBalancer:"
          kubectl -n monitoring get svc kube-prometheus-stack-grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "Pending..."
          echo " (user: admin, pass: admin)"
          echo ""
          echo "Prometheus (internal):"
          echo "kubectl port-forward -n monitoring svc/kube-prometheus-stack-prometheus 9090:9090"
          echo ""
