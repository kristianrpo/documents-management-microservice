name: Documents Microservice CD

on:
  push:
    branches: [main]

permissions:
  contents: read

env:
  TF_BACKEND_BUCKET: ${{ secrets.TF_BACKEND_BUCKET }}
  TF_BACKEND_KEY: infra/terraform/aws/terraform.tfstate
  TF_BACKEND_REGION: ${{ secrets.AWS_REGION }}
  TF_BACKEND_DDB_TABLE: ${{ secrets.TF_BACKEND_DDB_TABLE }}

jobs:
  infra-apply:
    name: Provision Microservice AWS Resources (Terraform) - Phase 1
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init (infra - remote state)
        working-directory: infra/terraform/aws
        run: |
          terraform init -input=false -upgrade \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Terraform Validate (infra)
        working-directory: infra/terraform/aws
        run: terraform validate

      - name: Terraform Apply (microservice resources)
        working-directory: infra/terraform/aws
        run: |
          terraform apply -auto-approve -input=false \
            -var "tf_backend_bucket=$TF_BACKEND_BUCKET"

  k8s-apply:
    name: Deploy Monitoring Stack (kube-prometheus) - Phase 2
    runs-on: ubuntu-latest
    needs: [infra-apply]
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init (infra dir to read outputs)
        working-directory: infra/terraform/aws
        run: |
          terraform init -input=false \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Read infra outputs (EKS cluster info from shared infra)
        id: infra_outputs
        run: |
          echo "CLUSTER_NAME=$(terraform -chdir=infra/terraform/aws output -raw cluster_name)" >> $GITHUB_OUTPUT
          echo "CLUSTER_ENDPOINT=$(terraform -chdir=infra/terraform/aws output -raw cluster_endpoint)" >> $GITHUB_OUTPUT
          echo "CLUSTER_CA=$(terraform -chdir=infra/terraform/aws output -raw cluster_ca_certificate)" >> $GITHUB_OUTPUT

      - name: Terraform Init (k8s - remote state)
        working-directory: k8s/terraform/aws
        run: |
          terraform init -input=false -upgrade \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=k8s/terraform/aws/terraform.tfstate" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Import existing K8s/Helm resources into state (idempotency)
        working-directory: k8s/terraform/aws
        env:
          TF_VAR_aws_region: ${{ secrets.AWS_REGION }}
          TF_VAR_cluster_name: ${{ steps.infra_outputs.outputs.CLUSTER_NAME }}
          TF_VAR_cluster_endpoint: ${{ steps.infra_outputs.outputs.CLUSTER_ENDPOINT }}
          TF_VAR_cluster_ca_certificate: ${{ steps.infra_outputs.outputs.CLUSTER_CA }}
        run: |
          set -euo pipefail
          # Importar namespace 'monitoring' si ya existe
          terraform import -input=false -no-color kubernetes_namespace.monitoring monitoring || true
          # Importar ConfigMap del dashboard si ya existe
          terraform import -input=false -no-color kubernetes_config_map.grafana_dashboard monitoring/documents-service-dashboard || true
          # Importar release Helm si ya existe
          terraform import -input=false -no-color helm_release.kube_prometheus_stack monitoring/kube-prometheus-stack || true

      - name: Terraform Validate (k8s)
        working-directory: k8s/terraform/aws
        run: terraform validate

      - name: Terraform Apply (monitoring stack)
        working-directory: k8s/terraform/aws
        env:
          TF_LOG: INFO
        run: |
          terraform apply -auto-approve -input=false \
            -var "aws_region=${{ secrets.AWS_REGION }}" \
            -var "cluster_name=${{ steps.infra_outputs.outputs.CLUSTER_NAME }}" \
            -var "cluster_endpoint=${{ steps.infra_outputs.outputs.CLUSTER_ENDPOINT }}" \
            -var "cluster_ca_certificate=${{ steps.infra_outputs.outputs.CLUSTER_CA }}"

  app-deploy:
    name: Deploy Application to EKS (kubectl/kustomize) - Phase 3
    runs-on: ubuntu-latest
    needs: [k8s-apply]
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Install kubectl
        run: |
          KUBECTL_VERSION=$(curl -sL https://dl.k8s.io/release/stable.txt)
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/kubectl
          kubectl version --client

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Setup Terraform (to read outputs from remote state)
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init (infra dir to read outputs)
        working-directory: infra/terraform/aws
        run: |
          terraform init -input=false \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE" \
            -backend-config="encrypt=true"

      - name: Update kubeconfig (connect kubectl to EKS)
        run: |
          CLUSTER_NAME=$(terraform -chdir=infra/terraform/aws output -raw cluster_name)
          aws eks update-kubeconfig --name "$CLUSTER_NAME" --region ${{ secrets.AWS_REGION }}

      - name: Prepare AWS Secrets for app
        env:
          TF_DIR: infra/terraform/aws
        run: |
          SECRET_NAME=$(terraform -chdir=$TF_DIR output -raw secretsmanager_secret_name)
          RABBIT_URL=$(terraform -chdir=$TF_DIR output -raw rabbitmq_amqp_url)
          S3_BUCKET=$(terraform -chdir=$TF_DIR output -raw s3_bucket)
          aws secretsmanager put-secret-value \
            --secret-id "$SECRET_NAME" \
            --secret-string "$(jq -n \
              --arg port "${{ secrets.APP_PORT }}" \
              --arg table "$(terraform -chdir=$TF_DIR output -raw dynamodb_table)" \
              --arg region "${{ secrets.AWS_REGION }}" \
              --arg bucket "$S3_BUCKET" \
              --arg rabbit "$RABBIT_URL" \
              --arg consumer_queue "${{ secrets.RABBITMQ_CONSUMER_QUEUE }}" \
              --arg auth_request_queue "${{ secrets.RABBITMQ_AUTH_REQUEST_QUEUE }}" \
              --arg auth_result_queue "${{ secrets.RABBITMQ_AUTH_RESULT_QUEUE }}" \
              '{
                APP_PORT: $port,
                DYNAMODB_TABLE: $table,
                DYNAMODB_ENDPOINT: "",
                AWS_REGION: $region,
                S3_BUCKET: $bucket,
                S3_ENDPOINT: "",
                S3_USE_PATH_STYLE: "false",
                S3_PUBLIC_BASE_URL: "",
                RABBITMQ_URL: $rabbit,
                RABBITMQ_CONSUMER_QUEUE: $consumer_queue,
                RABBITMQ_AUTH_REQUEST_QUEUE: $auth_request_queue,
                RABBITMQ_AUTH_RESULT_QUEUE: $auth_result_queue
              }')" || true

      - name: Render K8s templates with infra outputs
        env:
          TF_DIR: infra/terraform/aws
        run: |
          set -euo pipefail
          SECRET_NAME=$(terraform -chdir=$TF_DIR output -raw secretsmanager_secret_name)
          REGION='${{ secrets.AWS_REGION }}'
          # Sustituir placeholders en External Secrets
          sed -i "s|__AWS_REGION__|$REGION|g" k8s/externalsecrets.yaml
          sed -i "s|__AWS_SECRET_NAME__|$SECRET_NAME|g" k8s/externalsecrets.yaml

      - name: Deploy application
        run: |
          kubectl apply -k k8s/
          kubectl -n documents rollout status deploy/documents-service --timeout=180s

      - name: Display Access Information
        run: |
          echo "=== Deployment Summary ==="
          echo ""
          echo "Application Ingress (ALB):"
          kubectl -n documents get ingress documents-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "Pending..."
          echo ""
          echo ""
          echo "Grafana LoadBalancer:"
          kubectl -n monitoring get svc kube-prometheus-stack-grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "Pending..."
          echo " (user: admin, pass: admin)"
          echo ""
          echo "Prometheus (internal):"
          echo "kubectl port-forward -n monitoring svc/kube-prometheus-stack-prometheus 9090:9090"
          echo ""
